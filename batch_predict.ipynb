{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "sustainable-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "# from loky import ProcessPoolExecutor  # for Windows users\n",
    "\n",
    "def parallel(func, iterable):\n",
    "    e = ProcessPoolExecutor()\n",
    "    return e.map(func, iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "delayed-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "activated-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_extensions = ('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')\n",
    "\n",
    "def is_image_path_valid(path: Path):\n",
    "    return path.is_file() and path.suffix in image_file_extensions\n",
    "\n",
    "def verify_image(fn):\n",
    "    \"Confirm that `fn` can be opened\"\n",
    "    try:\n",
    "        im = Image.open(fn)\n",
    "        im.draft(im.mode, (32,32))\n",
    "        im.load()\n",
    "        return True\n",
    "    except: return False\n",
    "\n",
    "def load_image_file(path):\n",
    "    return Image.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "caroline-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_recursively(root_dir: Path):\n",
    "    ls = os.listdir\n",
    "    \n",
    "    images = []\n",
    "    label2image = []\n",
    "    \n",
    "    def append_if_image(root: Path, filename: str):\n",
    "        path = root / filename\n",
    "        \n",
    "        if is_image_path_valid(path):\n",
    "            images.append(path)\n",
    "            label2image.append(root.stem)\n",
    "        \n",
    "    for filename in ls(root_dir):\n",
    "        file_path = root_dir / filename\n",
    "            \n",
    "        if file_path.is_dir():\n",
    "            for nested_filename in ls(file_path):\n",
    "                append_if_image(file_path, nested_filename)\n",
    "        else:\n",
    "            append_if_image(root_dir, filename)\n",
    "            \n",
    "    return images, label2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "engaging-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "happy-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_paths = [Path(g) for g in glob(\"./data/new_image_crops/*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "perceived-lighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "impressed-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "corrected-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "mean_rgb = (131.0912, 103.8827, 91.4953)\n",
    "\n",
    "def load_image_for_feature_extraction(path='', shape=None):\n",
    "    '''\n",
    "    Referenced from VGGFace2 Paper:\n",
    "    Q. Cao, L. Shen, W. Xie, O. M. Parkhi, and A. Zisserman, “VGGFace2: A dataset for recognising faces across pose and age,” arXiv:1710.08092 [cs], May 2018\n",
    "    '''\n",
    "    short_size = 224.0\n",
    "    crop_size = shape\n",
    "    img = Image.open(path)\n",
    "    im_shape = np.array(img.size)    # in the format of (width, height, *)\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    ratio = float(short_size) / np.min(im_shape)\n",
    "    img = img.resize(size=(int(np.ceil(im_shape[0] * ratio)),   # width\n",
    "                           int(np.ceil(im_shape[1] * ratio))),  # height\n",
    "                     resample=Image.BILINEAR)\n",
    "\n",
    "    x = np.array(img)  # image has been transposed into (height, width)\n",
    "    newshape = x.shape[:2]\n",
    "    h_start = (newshape[0] - crop_size[0])//2\n",
    "    w_start = (newshape[1] - crop_size[1])//2\n",
    "    x = x[h_start:h_start+crop_size[0], w_start:w_start+crop_size[1]]\n",
    "    \n",
    "    # normalize colors to prevent overfitting on color differences \n",
    "    x = x - mean_rgb\n",
    "    \n",
    "    # returns transformed image, and original image\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "intelligent-knight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = load_image_for_feature_extraction(sample_paths[0] / \"0.jpg\", shape=(224,224,3))\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "postal-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "image_size = (224,224,3)\n",
    "\n",
    "def generate_batch(batch_size=16, shuffle=True):\n",
    "    total_samples = len(sample_paths)\n",
    "    \n",
    "    if shuffle:\n",
    "        idx = np.random.permutation(total_samples)\n",
    "    else:\n",
    "        idx = np.arange(total_samples)\n",
    "        \n",
    "    \n",
    "    for ndx in range(0, total_samples, batch_size):\n",
    "        batch_idx = idx[ndx: np.min([ndx + batch_size, total_samples])]\n",
    "        \n",
    "        batch_paths = np.array(sample_paths)[batch_idx]\n",
    "        \n",
    "        batch_images = []\n",
    "        batch_image2idx = []\n",
    "               \n",
    "        for i, (nid, path) in enumerate(zip(batch_idx, batch_paths)):\n",
    "            sub_image_paths = os.listdir(path)\n",
    "            \n",
    "            if(len(sub_image_paths) != 2):\n",
    "                warnings.warn(f\"{path} has {len(sub_image_paths)} files\")\n",
    "            else:\n",
    "                \n",
    "                batch_images.append(load_image_for_feature_extraction(path / sub_image_paths[0], image_size))\n",
    "                batch_images.append(load_image_for_feature_extraction(path / sub_image_paths[1], image_size))\n",
    "                batch_image2idx.extend([nid, nid])\n",
    "        \n",
    "        yield np.stack(batch_images), np.stack(batch_image2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dressed-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "lasso_model = joblib.load(\"./saved_model/lasso.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "static-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from saved_model.prepare_resnet50 import prepare_resnet_model\n",
    "\n",
    "resnet_model = prepare_resnet_model(\"./saved_model/resnet50_ft_weight.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "sweet-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def full_lime_pipeline(x):\n",
    "    x = torch.Tensor(x.transpose(0, 3, 1, 2))  # nx3x224x224\n",
    "    x = x.to(device)\n",
    "    x = resnet_model(x).detach().cpu().numpy()\n",
    "    return lasso_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "stable-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame({'sample_paths': sample_paths})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "announced-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['lasso_results_1'] = np.nan\n",
    "results['nn_results_1'] = np.nan\n",
    "results['lasso_results_2'] = np.nan\n",
    "results['nn_results_2'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "featured-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "coordinated-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "len_of_generator = math.ceil(len(sample_paths) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "postal-natural",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([592, 593]), array([0, 2]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(batch_image2idx, return_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "moral-candy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 149/149 [00:06<00:00, 21.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch_images, batch_image2idx in tqdm(generate_batch(shuffle=False, batch_size=batch_size), total=len_of_generator):\n",
    "    lasso_predictions = full_lime_pipeline(batch_images)\n",
    "    \n",
    "    unique_samples, unique_idx = np.unique(batch_image2idx, return_index=True)\n",
    "    \n",
    "    for sample_id, index in zip(unique_samples, unique_idx):\n",
    "        results.loc[[sample_id],'lasso_results_1'] = lasso_predictions[index]\n",
    "        results.loc[[sample_id],'lasso_results_2'] = lasso_predictions[index + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "blind-cleanup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_paths</th>\n",
       "      <th>lasso_results_1</th>\n",
       "      <th>nn_results_1</th>\n",
       "      <th>lasso_results_2</th>\n",
       "      <th>nn_results_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/new_image_crops/haircut face befoe after ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/new_image_crops/beard before after 3_28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/new_image_crops/beard before after face c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/new_image_crops/beard before after 2_20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/new_image_crops/makeup before after 4_15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>data/new_image_crops/drag queen face before af...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>data/new_image_crops/makeup before after chine...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>data/new_image_crops/makeup before after 3_24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>data/new_image_crops/hairdoo before and after ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>data/new_image_crops/makeupe before after 6_11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sample_paths  lasso_results_1  \\\n",
       "0    data/new_image_crops/haircut face befoe after ...              0.0   \n",
       "1         data/new_image_crops/beard before after 3_28              0.0   \n",
       "2    data/new_image_crops/beard before after face c...              1.0   \n",
       "3         data/new_image_crops/beard before after 2_20              0.0   \n",
       "4        data/new_image_crops/makeup before after 4_15              1.0   \n",
       "..                                                 ...              ...   \n",
       "590  data/new_image_crops/drag queen face before af...              0.0   \n",
       "591  data/new_image_crops/makeup before after chine...              0.0   \n",
       "592      data/new_image_crops/makeup before after 3_24              0.0   \n",
       "593  data/new_image_crops/hairdoo before and after ...              0.0   \n",
       "594     data/new_image_crops/makeupe before after 6_11              0.0   \n",
       "\n",
       "     nn_results_1  lasso_results_2  nn_results_2  \n",
       "0             NaN              1.0           NaN  \n",
       "1             NaN              0.0           NaN  \n",
       "2             NaN              1.0           NaN  \n",
       "3             NaN              0.0           NaN  \n",
       "4             NaN              0.0           NaN  \n",
       "..            ...              ...           ...  \n",
       "590           NaN              0.0           NaN  \n",
       "591           NaN              0.0           NaN  \n",
       "592           NaN              0.0           NaN  \n",
       "593           NaN              0.0           NaN  \n",
       "594           NaN              0.0           NaN  \n",
       "\n",
       "[595 rows x 5 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "experienced-package",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results['lasso_results_1'] != results['lasso_results_2']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "developmental-problem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['lasso_results_1'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "atlantic-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from saved_model.binary_classifier import load_pretrained_classifier\n",
    "\n",
    "binary_classifier = load_pretrained_classifier('./saved_model/weights-2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ignored-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_nn_pipeline(x):\n",
    "    x = torch.Tensor(x.transpose(0, 3, 1, 2))  # 1x3x224x224\n",
    "    x = x.to(device)\n",
    "    x = resnet_model(x)\n",
    "    x = torch.sigmoid(binary_classifier(x))\n",
    "    x = torch.round(x)\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "indonesian-refund",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_nn_pipeline(batch_images).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "medium-medium",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 149/149 [00:06<00:00, 24.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch_images, batch_image2idx in tqdm(generate_batch(shuffle=False, batch_size=batch_size), total=len_of_generator):\n",
    "    nn_predictions = full_nn_pipeline(batch_images)\n",
    "    \n",
    "    unique_samples, unique_idx = np.unique(batch_image2idx, return_index=True)\n",
    "    \n",
    "    for sample_id, index in zip(unique_samples, unique_idx):\n",
    "        results.loc[[sample_id],'nn_results_1'] = nn_predictions[index]\n",
    "        results.loc[[sample_id],'nn_results_2'] = nn_predictions[index + 1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "decent-panama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_paths</th>\n",
       "      <th>lasso_results_1</th>\n",
       "      <th>nn_results_1</th>\n",
       "      <th>lasso_results_2</th>\n",
       "      <th>nn_results_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/new_image_crops/haircut face befoe after ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/new_image_crops/beard before after 3_28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/new_image_crops/beard before after face c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/new_image_crops/beard before after 2_20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/new_image_crops/makeup before after 4_15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>data/new_image_crops/drag queen face before af...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>data/new_image_crops/makeup before after chine...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>data/new_image_crops/makeup before after 3_24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>data/new_image_crops/hairdoo before and after ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>data/new_image_crops/makeupe before after 6_11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sample_paths  lasso_results_1  \\\n",
       "0    data/new_image_crops/haircut face befoe after ...              0.0   \n",
       "1         data/new_image_crops/beard before after 3_28              0.0   \n",
       "2    data/new_image_crops/beard before after face c...              1.0   \n",
       "3         data/new_image_crops/beard before after 2_20              0.0   \n",
       "4        data/new_image_crops/makeup before after 4_15              1.0   \n",
       "..                                                 ...              ...   \n",
       "590  data/new_image_crops/drag queen face before af...              0.0   \n",
       "591  data/new_image_crops/makeup before after chine...              0.0   \n",
       "592      data/new_image_crops/makeup before after 3_24              0.0   \n",
       "593  data/new_image_crops/hairdoo before and after ...              0.0   \n",
       "594     data/new_image_crops/makeupe before after 6_11              0.0   \n",
       "\n",
       "     nn_results_1  lasso_results_2  nn_results_2  \n",
       "0             1.0              1.0           1.0  \n",
       "1             1.0              0.0           1.0  \n",
       "2             1.0              1.0           1.0  \n",
       "3             1.0              0.0           1.0  \n",
       "4             1.0              0.0           1.0  \n",
       "..            ...              ...           ...  \n",
       "590           1.0              0.0           0.0  \n",
       "591           1.0              0.0           1.0  \n",
       "592           1.0              0.0           1.0  \n",
       "593           1.0              0.0           1.0  \n",
       "594           0.0              0.0           1.0  \n",
       "\n",
       "[595 rows x 5 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ruled-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_1, lasso_2 = results['lasso_results_1'], results['lasso_results_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "approved-fitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lasso_1 != lasso_2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "minor-india",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results['nn_results_1'] != results['nn_results_2']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "senior-kelly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['lasso_results_1'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "sacred-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"./results/batch_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "honey-favorite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-lighting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
