{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conditional-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "# from loky import ProcessPoolExecutor  # for Windows users\n",
    "\n",
    "def parallel(func, iterable):\n",
    "    e = ProcessPoolExecutor()\n",
    "    return e.map(func, iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "falling-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from fastai.data.all import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "computational-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_extensions = ('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')\n",
    "\n",
    "def is_image_path_valid(path: Path):\n",
    "    return path.is_file() and path.suffix in image_file_extensions\n",
    "\n",
    "def load_image_file(path):\n",
    "    return Image.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "everyday-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_images_recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "limited-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path(\"./data/new_crops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "decimal-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = get_image_files(image_path / 'before')\n",
    "failed = verify_images(fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "invisible-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths(path: Path):\n",
    "    fns = get_image_files(path)\n",
    "    \n",
    "    return fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "executed-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_paths = load_image_paths(image_path / 'before')\n",
    "after_paths = load_image_paths(image_path / 'after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hybrid-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "mean_rgb = (131.0912, 103.8827, 91.4953)\n",
    "image_shape = (224,224,3)\n",
    "\n",
    "def load_image_for_feature_extraction(path='', shape=image_shape):\n",
    "    '''\n",
    "    Referenced from VGGFace2 Paper:\n",
    "    Q. Cao, L. Shen, W. Xie, O. M. Parkhi, and A. Zisserman, “VGGFace2: A dataset for recognising faces across pose and age,” arXiv:1710.08092 [cs], May 2018\n",
    "    '''\n",
    "    short_size = 224.0\n",
    "    crop_size = shape\n",
    "    img = Image.open(path)\n",
    "    im_shape = np.array(img.size)    # in the format of (width, height, *)\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    ratio = float(short_size) / np.min(im_shape)\n",
    "    img = img.resize(size=(int(np.ceil(im_shape[0] * ratio)),   # width\n",
    "                           int(np.ceil(im_shape[1] * ratio))),  # height\n",
    "                     resample=Image.BILINEAR)\n",
    "\n",
    "    x = np.array(img)  # image has been transposed into (height, width)\n",
    "    newshape = x.shape[:2]\n",
    "    h_start = (newshape[0] - crop_size[0])//2\n",
    "    w_start = (newshape[1] - crop_size[1])//2\n",
    "    x = x[h_start:h_start+crop_size[0], w_start:w_start+crop_size[1]]\n",
    "    \n",
    "    # normalize colors to prevent overfitting on color differences \n",
    "    x = x - mean_rgb\n",
    "    \n",
    "    # returns transformed image, and original image\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "forty-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "lasso_model = joblib.load(\"./saved_model/lasso.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "protecting-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "from saved_model.prepare_resnet50 import prepare_resnet_model\n",
    "\n",
    "resnet_model = prepare_resnet_model(\"./saved_model/resnet50_ft_weight.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "destroyed-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from saved_model.binary_classifier import load_pretrained_classifier\n",
    "\n",
    "binary_classifier = load_pretrained_classifier('./saved_model/weights-2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "paperback-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def full_lime_pipeline(x):\n",
    "    x = torch.Tensor(x.transpose(0, 3, 1, 2))  # nx3x224x224\n",
    "    x = x.to(device)\n",
    "    x = resnet_model(x).detach().cpu().numpy()\n",
    "    return lasso_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "velvet-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_nn_pipeline(x):\n",
    "    x = torch.Tensor(x.transpose(0, 3, 1, 2))  # 1x3x224x224\n",
    "    x = x.to(device)\n",
    "    x = resnet_model(x)\n",
    "    x = torch.sigmoid(binary_classifier(x))\n",
    "    x = torch.round(x)\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "honest-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame({'sample_paths': before_paths})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "prerequisite-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['lasso_results_1'] = np.nan\n",
    "results['nn_results_1'] = np.nan\n",
    "results['lasso_results_2'] = np.nan\n",
    "results['nn_results_2'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "historical-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "criminal-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(load_image_for_feature_extraction(before_paths[0]), 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "adult-appraisal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1292/1292 [00:56<00:00, 22.75it/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(path):\n",
    "    return np.expand_dims(load_image_for_feature_extraction(path), 0)\n",
    "\n",
    "for i, (before_path, after_path) in tqdm(enumerate(zip(before_paths, after_paths)), total=len(before_paths)):\n",
    "    if before_path.stem != after_path.stem:\n",
    "        print(f\"Before and after don't match for index {i}, before: {before_path}, after: {after_path}\")\n",
    "        break\n",
    "        \n",
    "    results.loc[i,'lasso_results_1'] = full_lime_pipeline(preprocess(before_path))\n",
    "    results.loc[i,'lasso_results_2'] = full_lime_pipeline(preprocess(after_path))\n",
    "    results.loc[i,'nn_results_1'] = full_nn_pipeline(preprocess(before_path)).squeeze()\n",
    "    results.loc[i,'nn_results_2'] = full_nn_pipeline(preprocess(after_path)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "temporal-india",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_paths</th>\n",
       "      <th>lasso_results_1</th>\n",
       "      <th>nn_results_1</th>\n",
       "      <th>lasso_results_2</th>\n",
       "      <th>nn_results_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/new_crops/before/haircut face before after 3_89.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/new_crops/before/makeup before after 3_108.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/new_crops/before/makeup before after 3_55.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/new_crops/before/makeup before after arabic_51.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/new_crops/before/beard before after 2_30.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>data/new_crops/before/makeup before after 3_39.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>data/new_crops/before/glasses before after 1_11.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>data/new_crops/before/beard before after 1_32.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>data/new_crops/before/haircut face before after 1_69.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>data/new_crops/before/beard before after face chinese 2_11.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1292 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        sample_paths  \\\n",
       "0           data/new_crops/before/haircut face before after 3_89.jpg   \n",
       "1                data/new_crops/before/makeup before after 3_108.jpg   \n",
       "2                 data/new_crops/before/makeup before after 3_55.jpg   \n",
       "3            data/new_crops/before/makeup before after arabic_51.jpg   \n",
       "4                  data/new_crops/before/beard before after 2_30.jpg   \n",
       "...                                                              ...   \n",
       "1287              data/new_crops/before/makeup before after 3_39.jpg   \n",
       "1288             data/new_crops/before/glasses before after 1_11.jpg   \n",
       "1289               data/new_crops/before/beard before after 1_32.jpg   \n",
       "1290        data/new_crops/before/haircut face before after 1_69.jpg   \n",
       "1291  data/new_crops/before/beard before after face chinese 2_11.jpg   \n",
       "\n",
       "      lasso_results_1  nn_results_1  lasso_results_2  nn_results_2  \n",
       "0                 1.0           1.0              0.0           1.0  \n",
       "1                 0.0           0.0              0.0           1.0  \n",
       "2                 0.0           0.0              0.0           0.0  \n",
       "3                 1.0           1.0              1.0           1.0  \n",
       "4                 0.0           0.0              0.0           0.0  \n",
       "...               ...           ...              ...           ...  \n",
       "1287              1.0           0.0              1.0           1.0  \n",
       "1288              0.0           0.0              0.0           0.0  \n",
       "1289              0.0           0.0              0.0           0.0  \n",
       "1290              0.0           0.0              0.0           1.0  \n",
       "1291              0.0           0.0              0.0           0.0  \n",
       "\n",
       "[1292 rows x 5 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "coordinated-netherlands",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(results)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "hollywood-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_1, lasso_2 = results['lasso_results_1'], results['lasso_results_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "knowing-database",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_flipped = (lasso_1 != lasso_2).sum()\n",
    "lasso_flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "first-decimal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_flipped = (results['nn_results_1'] != results['nn_results_2']).sum()\n",
    "nn_flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "suburban-invitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['lasso_results_1'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "expected-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"./results/batch_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "prospective-wichita",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_lib_to_con = len(results[(results['lasso_results_1'] == 0) & (results['lasso_results_2'] == 1)])\n",
    "lasso_lib_to_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "corporate-independence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_con_to_lib = len(results[(results['lasso_results_1'] == 1) & (results['lasso_results_2'] == 0)])\n",
    "lasso_con_to_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "distinct-calcium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_lib_to_con = len(results[(results['nn_results_1'] == 0) & (results['nn_results_2'] == 1)])\n",
    "nn_lib_to_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "timely-invitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_con_to_lib = len(results[(results['nn_results_1'] == 1) & (results['nn_results_2'] == 0)])\n",
    "nn_con_to_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "engaged-burst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33126934984520123"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_flipped / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-allen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
