{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "W041psec26km"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data.load_data import load_faces, load_features\n",
    "\n",
    "features = load_features()\n",
    "faces = load_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1634870799262,
     "user": {
      "displayName": "Rohan Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYtk9RJ4tvQkmTzl-z0jbeJ3r9CGjQZA8F6jwKOw=s64",
      "userId": "10846432523539896119"
     },
     "user_tz": 240
    },
    "id": "8elrw35hepty",
    "outputId": "4b6bbb92-9f7b-4e2c-933f-7f66f19cc257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# Check if GPU is available\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify that we want to use the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1634876151666,
     "user": {
      "displayName": "Rohan Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYtk9RJ4tvQkmTzl-z0jbeJ3r9CGjQZA8F6jwKOw=s64",
      "userId": "10846432523539896119"
     },
     "user_tz": 240
    },
    "id": "38RuMTtifnmm",
    "outputId": "c128a4ea-462a-4a80-b025-21ecec9c85b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1085795, 2048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TNA_dHNszpfw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = ['pol_dat_us', 'pol_dat_ca', 'pol_dat_uk', 'pol_fb_us']\n",
    "\n",
    "from utils import label_func, get_labels\n",
    "\n",
    "get_labels(faces.iloc[[1,2,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_nan_labels(colname):\n",
    "    col = faces[colname]\n",
    "    return col[col.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {k: get_not_nan_labels(k) for k in ground_truth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "HV7cgmwPrNvz"
   },
   "outputs": [],
   "source": [
    "# Randomly split training and testing datasets\n",
    "np.random.seed(67)\n",
    "torch.manual_seed(67)\n",
    "\n",
    "num_of_samples = features.shape[0]\n",
    "\n",
    "valid_sample_name = ground_truth[1]\n",
    "valid_sample = samples[valid_sample_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = np.array(valid_sample.index) - 1\n",
    "valid_y = np.array(valid_sample.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple binary classifier that takes a 2048 feature long tensor as input\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()        \n",
    "        \n",
    "        # Number of input features is 2048\n",
    "        self.layer_1 = nn.Linear(2048, 2048)\n",
    "        self.layer_2 = nn.Linear(2048, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "0rkOL3DxsANC"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, indexes, label_func=label_func):\n",
    "        self.indexes,self.label_func = indexes,label_func\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        index = self.indexes[i]\n",
    "        \n",
    "        sample = torch.tensor(features[index]).float()\n",
    "        label = label_func(faces.iloc[index])\n",
    "        \n",
    "        return sample,label\n",
    "    \n",
    "    def __len__(self): return len(self.indexes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    # Transform outputs to 0 and 1\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    # Calculate percentage of correct predictions\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses_and_metrics(losses, val_losses, accuracies, val_accuracies):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 3))\n",
    "\n",
    "    axes[0].plot(losses)\n",
    "    axes[0].plot(val_losses)\n",
    "    axes[0].set_title('model loss')\n",
    "    axes[0].set_ylabel('loss')\n",
    "    axes[0].set_xlabel('epoch')\n",
    "    axes[0].legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    axes[1].plot(accuracies)\n",
    "    axes[1].plot(val_accuracies)\n",
    "    axes[1].set_title('binary accuracy')\n",
    "    axes[1].set_ylabel('acc')\n",
    "    axes[1].set_xlabel('epoch')\n",
    "    axes[1].legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_sets(valid_set=1):\n",
    "    sample_to_exclude = ground_truth[valid_set]\n",
    "    \n",
    "    training_sample_names = [name for name in ground_truth if ground_truth != valid_set]\n",
    "    \n",
    "    def get_idx(sample):\n",
    "        return np.array(sample.index) - 1\n",
    "    \n",
    "    def get_y(sample):\n",
    "        return np.array(sample.values)\n",
    "    \n",
    "    train_idx = np.concatenate([get_idx(samples[n]) for n in training_sample_names])\n",
    "    train_y = np.concatenate([get_y(samples[n]) for n in training_sample_names])\n",
    "    valid_idx = get_idx(samples[sample_to_exclude])\n",
    "    valid_y = get_y(samples[sample_to_exclude])\n",
    "    \n",
    "    return train_idx, train_y, valid_idx, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, train_y, valid_idx, valid_y = get_data_sets(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1085795, 862770)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idx), len(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CustomDataset(train_idx)\n",
    "valid_ds = CustomDataset(valid_idx)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=64, num_workers=6)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=64, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "model = BinaryClassifier()\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████| 16966/16966 [01:04<00:00, 263.26training/s]\n",
      "100%|██████████████████████████████| 13481/13481 [00:41<00:00, 321.79training/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 0: | Training Loss: 0.61044 | Training accuracy: 0.6616339822514192 | Validation Loss: 0.7682439211309531 | Validation Accuracy: 0.6473471923438973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████| 16966/16966 [01:06<00:00, 256.25training/s]\n",
      "100%|██████████████████████████████| 13481/13481 [00:40<00:00, 334.02training/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 1: | Training Loss: 0.60557 | Training accuracy: 0.6664243665918291 | Validation Loss: 0.7621139514287398 | Validation Accuracy: 0.6469945200658076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████| 16966/16966 [01:05<00:00, 258.94training/s]\n",
      "100%|██████████████████████████████| 13481/13481 [00:43<00:00, 309.17training/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 2: | Training Loss: 0.60234 | Training accuracy: 0.6694972929064429 | Validation Loss: 0.7580559906910056 | Validation Accuracy: 0.6440267320662929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████| 16966/16966 [01:06<00:00, 255.80training/s]\n",
      "100%|██████████████████████████████| 13481/13481 [00:43<00:00, 308.12training/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 3: | Training Loss: 0.59902 | Training accuracy: 0.6727429122965839 | Validation Loss: 0.7538776902960453 | Validation Accuracy: 0.6419210833741281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████| 16966/16966 [01:06<00:00, 256.21training/s]\n",
      "100%|██████████████████████████████| 13481/13481 [00:42<00:00, 315.07training/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 4: | Training Loss: 0.59542 | Training accuracy: 0.6762597411221017 | Validation Loss: 0.7493382946356483 | Validation Accuracy: 0.6396528447419791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████| 16966/16966 [01:06<00:00, 254.12training/s]\n",
      "100%|██████████████████████████████| 13481/13481 [00:42<00:00, 319.15training/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 5: | Training Loss: 0.59164 | Training accuracy: 0.679928370397158 | Validation Loss: 0.7445863255755597 | Validation Accuracy: 0.6379969030492658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:  38%|████████▍             | 6522/16966 [00:26<00:41, 250.62training/s]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Move model to GPU if possible\n",
    "model = model.to(device)\n",
    "# Tells PyTorch we are in training mode\n",
    "model.train()\n",
    "\n",
    "try:\n",
    "    for e in range(EPOCHS):\n",
    "\n",
    "        # Set loss and accuracy to zero at start of each epoch\n",
    "        epoch_training_loss = 0\n",
    "        epoch_training_accuracy = 0\n",
    "        epoch_valid_loss = 0\n",
    "        epoch_valid_accuracy = 0\n",
    "\n",
    "        with tqdm(train_dl, unit=\"training\", total=len(train_dl)) as tepoch:\n",
    "            for x_batch, y_batch in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {e}\")\n",
    "                # Transfer the tensors to the GPU if possible\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "                # Zero out gradients before backpropagation (PyTorch cumulates the gradient otherwise)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Predict a minibatch of outputs\n",
    "                y_pred = model(x_batch)\n",
    "\n",
    "                # Calculate the loss (unsqueeze adds a dimension to y)\n",
    "                loss = loss_function(y_pred, y_batch.unsqueeze(1))\n",
    "                training_acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "                # Backpropagation. Gradients are calculated\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_loss = loss.item()\n",
    "                batch_acc = training_acc.item()\n",
    "                epoch_training_loss += batch_loss\n",
    "                epoch_training_accuracy += batch_acc\n",
    "                losses.append(batch_loss)\n",
    "                accuracies.append(batch_acc)\n",
    "                \n",
    "                # tepoch.set_postfix(loss=loss.item(), accuracy=100. * training_acc.item())\n",
    "\n",
    "        with tqdm(valid_dl, unit=\"training\", total=len(valid_dl)) as tepoch:\n",
    "            for x_batch, y_batch in tepoch:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "                valid_y_pred = model(x_batch)\n",
    "                valid_loss = loss_function(valid_y_pred, y_batch.unsqueeze(1))\n",
    "                valid_acc = binary_acc(valid_y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "                batch_valid_loss = valid_loss.item()\n",
    "                batch_valid_accuracy = valid_acc.item()\n",
    "                epoch_valid_loss += batch_valid_loss\n",
    "                epoch_valid_accuracy += batch_valid_accuracy\n",
    "                val_losses.append(batch_valid_loss)\n",
    "                val_accuracies.append(batch_valid_accuracy)\n",
    "\n",
    "        avg_train_loss = epoch_training_loss/len(train_dl)\n",
    "        avg_valid_loss = epoch_training_loss/len(valid_dl)\n",
    "\n",
    "        avg_train_accuracy = epoch_training_accuracy/len(train_dl)\n",
    "        avg_valid_accuracy = epoch_valid_accuracy/len(valid_dl)\n",
    "\n",
    "        print(f'End of Epoch {e}: | Training Loss: {avg_train_loss:.5f} | Training accuracy: {avg_train_accuracy} | Validation Loss: {avg_valid_loss} | Validation Accuracy: {avg_valid_accuracy}')\n",
    "  \n",
    "except Exception as e:\n",
    "    print(\"Something went wrong in training\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "XDIEghli_AdB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217159"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_list = np.array([])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in valid_dl:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_tag = y_pred_tag.squeeze(1).cpu().numpy()\n",
    "        y_pred_list = np.append(y_pred_list, y_pred_tag)\n",
    "                     \n",
    "len(y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './saved_model/weights-2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_nan_labels(colname):\n",
    "    col = faces[colname]\n",
    "    return col[col.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ['pol_dat_us', 'pol_dat_ca', 'pol_dat_uk', 'pol_fb_us']\n",
    "samples = {k: get_not_nan_labels(k) for k in ground_truth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample pol_dat_us: : 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 0: | Training Loss: 1.21762 | Training accuracy: 0.5854974593874627 | Validation Loss: 4.836399648151718 | Validation Accuracy: 0.5864419353556197\n",
      "End of Epoch 1: | Training Loss: 1.21176 | Training accuracy: 0.5885336306627281 | Validation Loss: 4.813125032944689 | Validation Accuracy: 0.5921748726945382\n",
      "End of Epoch 2: | Training Loss: 1.14215 | Training accuracy: 0.5927725595285787 | Validation Loss: 4.536643441116376 | Validation Accuracy: 0.5836764195419158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample pol_dat_ca: : 1it [03:41, 221.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 3: | Training Loss: 1.07523 | Training accuracy: 0.5944138973361085 | Validation Loss: 4.270829016213951 | Validation Accuracy: 0.5828569587287161\n",
      "End of Epoch 0: | Training Loss: 1.06064 | Training accuracy: 0.6173057673770661 | Validation Loss: 0.32781731031743544 | Validation Accuracy: 0.5153329931045885\n",
      "End of Epoch 1: | Training Loss: 1.22054 | Training accuracy: 0.6242760962480812 | Validation Loss: 0.37723687746236423 | Validation Accuracy: 0.5527006692582885\n",
      "End of Epoch 2: | Training Loss: 1.27672 | Training accuracy: 0.6379647282785865 | Validation Loss: 0.3946010704988076 | Validation Accuracy: 0.5328086855029386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample pol_dat_uk: : 2it [04:45, 128.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 3: | Training Loss: 1.25659 | Training accuracy: 0.6510867492941247 | Validation Loss: 0.38837942625420213 | Validation Accuracy: 0.5352210308182008\n",
      "End of Epoch 0: | Training Loss: 1.04045 | Training accuracy: 0.5888155361361433 | Validation Loss: 0.229609266770143 | Validation Accuracy: 0.5217295226870948\n",
      "End of Epoch 1: | Training Loss: 1.34689 | Training accuracy: 0.6033926645967767 | Validation Loss: 0.29723658561527655 | Validation Accuracy: 0.5796935505985019\n",
      "End of Epoch 2: | Training Loss: 1.44451 | Training accuracy: 0.6190642010226587 | Validation Loss: 0.3187786445328455 | Validation Accuracy: 0.5723552329791737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample pol_fb_us: : 3it [05:45, 97.55s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 3: | Training Loss: 1.43196 | Training accuracy: 0.633432718001316 | Validation Loss: 0.31600981920363247 | Validation Accuracy: 0.5225371453926433\n",
      "End of Epoch 0: | Training Loss: 1.20367 | Training accuracy: 0.6311618779649102 | Validation Loss: 0.5986447097718136 | Validation Accuracy: 0.5919170647982506\n",
      "End of Epoch 1: | Training Loss: 1.15676 | Training accuracy: 0.6424537173944627 | Validation Loss: 0.5753120152145365 | Validation Accuracy: 0.5599751925742409\n",
      "End of Epoch 2: | Training Loss: 1.31015 | Training accuracy: 0.652107153423307 | Validation Loss: 0.6516000181866565 | Validation Accuracy: 0.5545704341770694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample pol_fb_us: : 4it [06:58, 104.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 3: | Training Loss: 1.29072 | Training accuracy: 0.6599829679981792 | Validation Loss: 0.6419389991751582 | Validation Accuracy: 0.5684052477110535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 4\n",
    "\n",
    "\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "with tqdm(enumerate(ground_truth)) as t:\n",
    "    for i, sample_name in t:\n",
    "        losses = []\n",
    "        val_losses = []\n",
    "        accuracies = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        t.set_description(f'Sample {sample_name}')\n",
    "        model = BinaryClassifier()\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        \n",
    "        sample = samples[sample_name]\n",
    "        train_idx = np.array(sample.index) - 1\n",
    "        train_y = np.array(sample.values)\n",
    "        valid_sample_name = ground_truth[i + 1] if i < len(ground_truth) - 1 else ground_truth[0]\n",
    "        valid_sample = samples[valid_sample_name]\n",
    "        \n",
    "        train_ds = CustomDataset(train_idx)\n",
    "        valid_ds = CustomDataset(valid_idx)\n",
    "        train_dl = DataLoader(train_ds, batch_size=64, num_workers=6)\n",
    "        valid_dl = DataLoader(valid_ds, batch_size=64, num_workers=6)\n",
    "        \n",
    "        for e in range(EPOCHS):\n",
    "\n",
    "            # Set loss and accuracy to zero at start of each epoch\n",
    "            epoch_training_loss = 0\n",
    "            epoch_training_accuracy = 0\n",
    "            epoch_valid_loss = 0\n",
    "            epoch_valid_accuracy = 0\n",
    "\n",
    "            for x_batch, y_batch in train_dl:\n",
    "                # Transfer the tensors to the GPU if possible\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "                # Zero out gradients before backpropagation (PyTorch cumulates the gradient otherwise)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Predict a minibatch of outputs\n",
    "                y_pred = model(x_batch)\n",
    "\n",
    "                # Calculate the loss (unsqueeze adds a dimension to y)\n",
    "                loss = loss_function(y_pred, y_batch.unsqueeze(1))\n",
    "                training_acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "                # Backpropagation. Gradients are calculated\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_loss = loss.item()\n",
    "                batch_acc = training_acc.item()\n",
    "                epoch_training_loss += batch_loss\n",
    "                epoch_training_accuracy += batch_acc\n",
    "                losses.append(batch_loss)\n",
    "                accuracies.append(batch_acc)\n",
    "\n",
    "                # tepoch.set_postfix(loss=loss.item(), accuracy=100. * training_acc.item())\n",
    "\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "                valid_y_pred = model(x_batch)\n",
    "                valid_loss = loss_function(valid_y_pred, y_batch.unsqueeze(1))\n",
    "                valid_acc = binary_acc(valid_y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "                batch_valid_loss = valid_loss.item()\n",
    "                batch_valid_accuracy = valid_acc.item()\n",
    "                epoch_valid_loss += batch_valid_loss\n",
    "                epoch_valid_accuracy += batch_valid_accuracy\n",
    "                val_losses.append(batch_valid_loss)\n",
    "                val_accuracies.append(batch_valid_accuracy)\n",
    "\n",
    "            avg_train_loss = epoch_training_loss/len(train_dl)\n",
    "            # avg_valid_loss = epoch_training_loss/len(valid_dl)\n",
    "\n",
    "            avg_train_accuracy = epoch_training_accuracy/len(train_dl)\n",
    "            # avg_valid_accuracy = epoch_valid_accuracy/len(valid_dl)\n",
    "\n",
    "            print(f'End of Epoch {e}: | Training Loss: {avg_train_loss:.5f} | Training accuracy: {avg_train_accuracy})\n",
    "\n",
    "            models[sample_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample pol_fb_us:   0%| | 0/4 [03:50<?, ?it/s, accuracy=tensor(0.0007, device='c\n"
     ]
    }
   ],
   "source": [
    "acc_matrix = np.zeros([4,4])\n",
    "\n",
    "with tqdm(enumerate(ground_truth), total=4) as t:\n",
    "    for i, sample_name in enumerate(ground_truth):\n",
    "        t.set_description(f'Sample {sample_name}')\n",
    "        model = models[sample_name]\n",
    "        model.to(device)\n",
    "        \n",
    "        for j, test_sample in enumerate(ground_truth):\n",
    "            t.set_postfix({'imputing':test_sample})\n",
    "            \n",
    "            sample = samples[test_sample]\n",
    "            indexes = np.array(sample.index) - 1\n",
    "            values = np.array(sample.values)\n",
    "            \n",
    "            valid_ds = CustomDataset(indexes)\n",
    "            valid_dl = DataLoader(valid_ds, batch_size=64, num_workers=6)\n",
    "            \n",
    "            valid_acc = 0\n",
    "            \n",
    "             \n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "                valid_y_pred = model(x_batch)\n",
    "                valid_acc = binary_acc(valid_y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "                batch_valid_accuracy = valid_acc.item()\n",
    "                valid_acc += batch_valid_accuracy\n",
    "                \n",
    "            avg_valid_accuracy = valid_acc/len(valid_dl).c\n",
    "            t.set_postfix({'accuracy':avg_valid_accuracy})\n",
    "            acc_matrix[i,j] = avg_valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.09784145e-04, 9.91420355e-04, 1.23241264e-03, 6.16113772e-04],\n",
       "       [8.90141673e-05, 1.29647285e-03, 1.64321670e-03, 7.34597212e-04],\n",
       "       [5.93427758e-05, 8.77025712e-04, 2.67022708e-03, 5.92417084e-04],\n",
       "       [9.19813101e-05, 8.77025712e-04, 1.43781467e-03, 7.34597212e-04]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1688"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1687"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ds) // 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6599999666213989"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO0fLK1v0FHPC7K2mZ78993",
   "mount_file_id": "1Gv9P6j20Iz6psk8kmk82m4fBHJmy2O-r",
   "name": "tabular_nn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
