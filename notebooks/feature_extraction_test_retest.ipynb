{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mysterious-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from fastai.data.all import get_image_files\n",
    "# from fastai.vision.all import *\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "level-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import sys\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "sys.path.insert(0, currentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adjustable-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_images_recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "republican-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_extensions = ('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')\n",
    "\n",
    "def is_image_path_valid(path: Path):\n",
    "    return path.is_file() and path.suffix in image_file_extensions\n",
    "\n",
    "def load_image_file(path):\n",
    "    return Image.open(path)\n",
    "\n",
    "image_dir = Path(\"../data/before_after_images/processed\")\n",
    "\n",
    "def load_image_paths(path: Path):\n",
    "    fns = get_image_files(path)\n",
    "    \n",
    "    return fns\n",
    "\n",
    "before_paths = load_image_paths(image_dir / 'before')\n",
    "after_paths = load_image_paths(image_dir / 'after')\n",
    "\n",
    "mean_rgb = (131.0912, 103.8827, 91.4953)\n",
    "image_shape = (224,224,3)\n",
    "\n",
    "def load_image_for_feature_extraction(path='', shape=image_shape):\n",
    "    '''\n",
    "    Referenced from VGGFace2 Paper:\n",
    "    Q. Cao, L. Shen, W. Xie, O. M. Parkhi, and A. Zisserman, “VGGFace2: A dataset for recognising faces across pose and age,” arXiv:1710.08092 [cs], May 2018\n",
    "    '''\n",
    "    short_size = 224.0\n",
    "    crop_size = shape\n",
    "    img = Image.open(path)\n",
    "    im_shape = np.array(img.size)    # in the format of (width, height, *)\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    ratio = float(short_size) / np.min(im_shape)\n",
    "    img = img.resize(size=(int(np.ceil(im_shape[0] * ratio)),   # width\n",
    "                           int(np.ceil(im_shape[1] * ratio))),  # height\n",
    "                     resample=Image.BILINEAR)\n",
    "\n",
    "    x = np.array(img)  # image has been transposed into (height, width)\n",
    "    newshape = x.shape[:2]\n",
    "    h_start = (newshape[0] - crop_size[0])//2\n",
    "    w_start = (newshape[1] - crop_size[1])//2\n",
    "    x = x[h_start:h_start+crop_size[0], w_start:w_start+crop_size[1]]\n",
    "    \n",
    "    # normalize colors to prevent overfitting on color differences \n",
    "    x = x - mean_rgb\n",
    "    \n",
    "    # returns transformed image, and original image\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "induced-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from saved_model.prepare_resnet50 import prepare_resnet_model\n",
    "\n",
    "resnet_model = prepare_resnet_model(\"../saved_model/resnet50_ft_weight.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fleet-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def full_pipeline(x):\n",
    "    x = torch.Tensor(x.transpose(0, 3, 1, 2))  # nx3x224x224\n",
    "    x = x.to(device)\n",
    "    x = resnet_model(x).detach().cpu()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "palestinian-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path):\n",
    "    return np.expand_dims(load_image_for_feature_extraction(path), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "directed-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_features = torch.empty((len(before_paths), 2048))\n",
    "after_features = torch.empty((len(after_paths), 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "devoted-enlargement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1292/1292 [00:25<00:00, 50.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, (before_path, after_path) in tqdm(enumerate(zip(before_paths, after_paths)), total=len(before_paths)):\n",
    "    if before_path.stem != after_path.stem:\n",
    "        print(f\"Before and after don't match for index {i}, before: {before_path}, after: {after_path}\")\n",
    "        break\n",
    "        \n",
    "    before_features[i] = full_pipeline(preprocess(before_path)).squeeze()\n",
    "    after_features[i] = full_pipeline(preprocess(after_path)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "extraordinary-group",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1049, 0.0000, 2.3196,  ..., 2.6292, 2.7984, 0.0230])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_features[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "differential-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(before_features, \"../data/before_after_images/features/resnet_50_vggface2/before/list_of_tensors.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "competitive-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(after_features, \"../data/before_after_images/features/resnet_50_vggface2/after/list_of_tensors.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-indication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
