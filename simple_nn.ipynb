{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in ./env/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.0 in ./env/lib/python3.8/site-packages (from seaborn) (1.7.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in ./env/lib/python3.8/site-packages (from seaborn) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.15 in ./env/lib/python3.8/site-packages (from seaborn) (1.21.3)\n",
      "Requirement already satisfied: pandas>=0.23 in ./env/lib/python3.8/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: cycler>=0.10 in ./env/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./env/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./env/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (3.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./env/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./env/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six in ./env/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "p0Ljc86Nd5VB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1634870799262,
     "user": {
      "displayName": "Rohan Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYtk9RJ4tvQkmTzl-z0jbeJ3r9CGjQZA8F6jwKOw=s64",
      "userId": "10846432523539896119"
     },
     "user_tz": 240
    },
    "id": "8elrw35hepty",
    "outputId": "4b6bbb92-9f7b-4e2c-933f-7f66f19cc257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# Check if GPU is available\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "W041psec26km"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "K9_u1YabfLRs"
   },
   "outputs": [],
   "source": [
    "# Load a small chunk of the full dataset for testing purposes\n",
    "faces = pd.read_csv('./faces_smaller_chunk.csv')\n",
    "features = pd.read_csv('./vgg_chunks/chunk_1.csv', usecols=range(1, 2049))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1634876140507,
     "user": {
      "displayName": "Rohan Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYtk9RJ4tvQkmTzl-z0jbeJ3r9CGjQZA8F6jwKOw=s64",
      "userId": "10846432523539896119"
     },
     "user_tz": 240
    },
    "id": "0Y_TyhY0fd4j",
    "outputId": "ff9a10a6-7c26-40d2-9b2c-779a091db7e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userid</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>facial_hair</th>\n",
       "      <th>pol</th>\n",
       "      <th>pol_dat_us</th>\n",
       "      <th>pol_dat_ca</th>\n",
       "      <th>pol_dat_uk</th>\n",
       "      <th>...</th>\n",
       "      <th>left_eye_status.no_glass_eye_open</th>\n",
       "      <th>left_eye_status.normal_glass_eye_close</th>\n",
       "      <th>left_eye_status.dark_glasses</th>\n",
       "      <th>right_eye_status.normal_glass_eye_open</th>\n",
       "      <th>right_eye_status.no_glass_eye_close</th>\n",
       "      <th>right_eye_status.occlusion</th>\n",
       "      <th>right_eye_status.no_glass_eye_open</th>\n",
       "      <th>right_eye_status.normal_glass_eye_close</th>\n",
       "      <th>right_eye_status.dark_glasses</th>\n",
       "      <th>ethnicity.value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>liberal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>liberal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td>0.977098</td>\n",
       "      <td>conservative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>39.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.2</td>\n",
       "      <td>india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.36</td>\n",
       "      <td>united states</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>liberal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>98.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>81.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>liberal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  userid  gender    age        country  facial_hair  \\\n",
       "0           1       1     0.0    NaN  united states     0.001713   \n",
       "1           2       2     1.0    NaN  united states     0.005151   \n",
       "2           3       3     0.0    NaN  united states     0.977098   \n",
       "3           4       4     1.0  24.36  united states     0.000478   \n",
       "4           5       5     1.0    NaN  united states     0.005617   \n",
       "\n",
       "            pol  pol_dat_us  pol_dat_ca  pol_dat_uk  ...  \\\n",
       "0       liberal         NaN         NaN         NaN  ...   \n",
       "1       liberal         NaN         NaN         NaN  ...   \n",
       "2  conservative         NaN         NaN         NaN  ...   \n",
       "3       liberal         NaN         NaN         NaN  ...   \n",
       "4       liberal         NaN         NaN         NaN  ...   \n",
       "\n",
       "   left_eye_status.no_glass_eye_open  left_eye_status.normal_glass_eye_close  \\\n",
       "0                                1.8                                     0.0   \n",
       "1                              100.0                                     0.0   \n",
       "2                                0.3                                     0.0   \n",
       "3                               98.9                                     0.0   \n",
       "4                                0.0                                     0.0   \n",
       "\n",
       "   left_eye_status.dark_glasses  right_eye_status.normal_glass_eye_open  \\\n",
       "0                           0.0                                     0.0   \n",
       "1                           0.0                                     0.0   \n",
       "2                          15.5                                    39.7   \n",
       "3                           0.5                                     0.0   \n",
       "4                           0.0                                     2.3   \n",
       "\n",
       "   right_eye_status.no_glass_eye_close  right_eye_status.occlusion  \\\n",
       "0                                  0.0                        99.9   \n",
       "1                                  0.0                         0.0   \n",
       "2                                  0.0                         0.0   \n",
       "3                                  0.0                        10.2   \n",
       "4                                  0.0                        97.3   \n",
       "\n",
       "  right_eye_status.no_glass_eye_open  right_eye_status.normal_glass_eye_close  \\\n",
       "0                                0.1                                      0.0   \n",
       "1                              100.0                                      0.0   \n",
       "2                                0.0                                      0.0   \n",
       "3                               81.7                                      0.0   \n",
       "4                                0.1                                      0.1   \n",
       "\n",
       "   right_eye_status.dark_glasses  ethnicity.value  \n",
       "0                            0.0            black  \n",
       "1                            0.0            black  \n",
       "2                           60.2            india  \n",
       "3                            8.1            black  \n",
       "4                            0.2            asian  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1634876151666,
     "user": {
      "displayName": "Rohan Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYtk9RJ4tvQkmTzl-z0jbeJ3r9CGjQZA8F6jwKOw=s64",
      "userId": "10846432523539896119"
     },
     "user_tz": 240
    },
    "id": "38RuMTtifnmm",
    "outputId": "c128a4ea-462a-4a80-b025-21ecec9c85b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10859, 2048)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mSDaR2uSkPCS"
   },
   "outputs": [],
   "source": [
    "features_tensor = torch.tensor(features.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1634876151668,
     "user": {
      "displayName": "Rohan Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYtk9RJ4tvQkmTzl-z0jbeJ3r9CGjQZA8F6jwKOw=s64",
      "userId": "10846432523539896119"
     },
     "user_tz": 240
    },
    "id": "xICurphSkgYE",
    "outputId": "4217bfac-d1b4-47e7-b2bf-83dfc2919f3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10859, 2048])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TNA_dHNszpfw"
   },
   "outputs": [],
   "source": [
    "ground_truth = ['pol_dat_us', 'pol_dat_ca', 'pol_dat_uk', 'pol_fb_us']\n",
    "\n",
    "def label_func(row):\n",
    "    '''\n",
    "    Checks each column of ground_truth and extracts whichever column is not null as the label\n",
    "    '''\n",
    "    for i in ground_truth:\n",
    "        if ~np.isnan(row[i]):\n",
    "            return row[i]\n",
    "    return np.nan\n",
    "\n",
    "def get_labels(data):\n",
    "    '''\n",
    "    Returns array of labels from entire dataset\n",
    "    '''\n",
    "    return data.apply(lambda row: label_func(row), axis=1).to_numpy()\n",
    "\n",
    "get_labels(faces.iloc[[1,2,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HV7cgmwPrNvz"
   },
   "outputs": [],
   "source": [
    "# Randomly split training and testing datasets\n",
    "num_of_samples = features_tensor.shape[0]\n",
    "idx = np.random.permutation(range(num_of_samples))\n",
    "\n",
    "cut = int(0.8 * num_of_samples)\n",
    "train_idx = idx[:cut]\n",
    "train_x = features_tensor[train_idx]\n",
    "train_y = get_labels(faces.iloc[train_idx])\n",
    "\n",
    "valid_idx = idx[cut:]\n",
    "valid_x = features_tensor[valid_idx]\n",
    "valid_y = get_labels(faces.iloc[valid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0rkOL3DxsANC"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data,self.labels = data,labels\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        sample = self.data[i]\n",
    "        label = self.labels[i]\n",
    "        return sample,label\n",
    "    \n",
    "    def __len__(self): return len(self.data)\n",
    "\n",
    "train_ds = CustomDataset(train_x, train_y)\n",
    "valid_ds = CustomDataset(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6_HrPqMq3Bjb"
   },
   "outputs": [],
   "source": [
    "# Dataloader will be passing a batch of 64 samples at a time to our model\n",
    "train_dl = DataLoader(train_ds, batch_size=64)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple binary classifier that takes a 2048 feature long tensor as input\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()        \n",
    "        \n",
    "        # Number of input features is 2048\n",
    "        self.layer_1 = nn.Linear(2048, 1024) \n",
    "        self.layer_2 = nn.Linear(1024, 480)\n",
    "        self.layer_3 = nn.Linear(480, 240)\n",
    "        self.layer_4 = nn.Linear(240, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(1024)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(480)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(240)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = BinaryClassifier()\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6764],\n",
       "        [ 0.1567],\n",
       "        [-0.2527],\n",
       "        ...,\n",
       "        [ 0.2894],\n",
       "        [-1.0348],\n",
       "        [-0.2516]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a minibatch of data through the model to check we get any errors\n",
    "minibatch = train_x[:64]\n",
    "model\n",
    "model(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    # Transform outputs to 0 and 1\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    # Calculate percentage of correct predictions\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify that we want to use the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: | Training Loss: 0.66802 | Training accuracy: 59.01470588235294 | Validation Loss: 2.6720792487227545 | Validation Accuracy: 59.529411764705884\n",
      "Epoch 1: | Training Loss: 0.50308 | Training accuracy: 77.33823529411765 | Validation Loss: 2.012335631463454 | Validation Accuracy: 61.05882352941177\n",
      "Epoch 2: | Training Loss: 0.35523 | Training accuracy: 89.11029411764706 | Validation Loss: 1.4209346602368957 | Validation Accuracy: 60.73529411764706\n",
      "Epoch 3: | Training Loss: 0.21611 | Training accuracy: 96.11029411764706 | Validation Loss: 0.8644352900056875 | Validation Accuracy: 62.38235294117647\n",
      "Epoch 4: | Training Loss: 0.12393 | Training accuracy: 98.55882352941177 | Validation Loss: 0.49570416327149613 | Validation Accuracy: 61.88235294117647\n",
      "Epoch 5: | Training Loss: 0.09151 | Training accuracy: 98.70588235294117 | Validation Loss: 0.3660219546958513 | Validation Accuracy: 63.14705882352941\n",
      "Epoch 6: | Training Loss: 0.07900 | Training accuracy: 98.65441176470588 | Validation Loss: 0.3160019896050792 | Validation Accuracy: 61.73529411764706\n",
      "Epoch 7: | Training Loss: 0.07875 | Training accuracy: 98.17647058823529 | Validation Loss: 0.315005522722729 | Validation Accuracy: 62.26470588235294\n",
      "Epoch 8: | Training Loss: 0.08351 | Training accuracy: 97.44852941176471 | Validation Loss: 0.3340287958711787 | Validation Accuracy: 62.1764705882353\n",
      "Epoch 9: | Training Loss: 0.07149 | Training accuracy: 98.06617647058823 | Validation Loss: 0.28595811509177027 | Validation Accuracy: 62.35294117647059\n",
      "Epoch 10: | Training Loss: 0.06375 | Training accuracy: 98.05147058823529 | Validation Loss: 0.2550008126078337 | Validation Accuracy: 62.73529411764706\n",
      "Epoch 11: | Training Loss: 0.04755 | Training accuracy: 98.66176470588235 | Validation Loss: 0.19020250893456786 | Validation Accuracy: 62.3235294117647\n",
      "Epoch 12: | Training Loss: 0.02915 | Training accuracy: 99.38235294117646 | Validation Loss: 0.1166069292577476 | Validation Accuracy: 63.94117647058823\n",
      "Epoch 13: | Training Loss: 0.01992 | Training accuracy: 99.69117647058823 | Validation Loss: 0.07966247078416647 | Validation Accuracy: 62.5\n",
      "Epoch 14: | Training Loss: 0.01340 | Training accuracy: 99.91176470588235 | Validation Loss: 0.053584495796555054 | Validation Accuracy: 63.26470588235294\n",
      "Epoch 15: | Training Loss: 0.00909 | Training accuracy: 99.97058823529412 | Validation Loss: 0.036347253840763434 | Validation Accuracy: 63.23529411764706\n",
      "Epoch 16: | Training Loss: 0.00650 | Training accuracy: 99.98529411764706 | Validation Loss: 0.026010230283331093 | Validation Accuracy: 62.970588235294116\n",
      "Epoch 17: | Training Loss: 0.00464 | Training accuracy: 100.0 | Validation Loss: 0.01856166028607767 | Validation Accuracy: 64.05882352941177\n",
      "Epoch 18: | Training Loss: 0.00372 | Training accuracy: 100.0 | Validation Loss: 0.014875164398257808 | Validation Accuracy: 63.411764705882355\n",
      "Epoch 19: | Training Loss: 0.00308 | Training accuracy: 100.0 | Validation Loss: 0.012302139886765255 | Validation Accuracy: 63.5\n"
     ]
    }
   ],
   "source": [
    "# Move model to GPU if possible\n",
    "model = model.to(device)\n",
    "# Tells PyTorch we are in training mode\n",
    "model.train()\n",
    "\n",
    "for e in range(0, EPOCHS):\n",
    "    \n",
    "    # Set loss and accuracy to zero at start of each epoch\n",
    "    epoch_training_loss = 0\n",
    "    epoch_training_accuracy = 0\n",
    "    epoch_valid_loss = 0\n",
    "    epoch_valid_accuracy = 0\n",
    "    \n",
    "    for x_batch, y_batch in train_dl:\n",
    "        # Transfer the tensors to the GPU if possible\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # Zero out gradients before backpropagation (PyTorch cumulates the gradient otherwise)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Predict a minibatch of outputs\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        # Calculate the loss (unsqueeze adds a dimension to y)\n",
    "        loss = loss_function(y_pred, y_batch.unsqueeze(1))\n",
    "        training_acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        # Backpropagation. Gradients are calculated\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_training_loss += loss.item()\n",
    "        epoch_training_accuracy += training_acc.item()\n",
    "    \n",
    "    for x_batch, y_batch in valid_dl:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        valid_y_pred = model(x_batch)\n",
    "        valid_loss = loss_function(valid_y_pred, y_batch.unsqueeze(1))\n",
    "        valid_acc = binary_acc(valid_y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        epoch_valid_loss += valid_loss.item()\n",
    "        epoch_valid_accuracy += valid_acc.item()\n",
    "        \n",
    "    avg_train_loss = epoch_training_loss/len(train_dl)\n",
    "    avg_valid_loss = epoch_training_loss/len(valid_dl)\n",
    "    \n",
    "    avg_train_accuracy = epoch_training_accuracy/len(train_dl)\n",
    "    avg_valid_accuracy = epoch_valid_accuracy/len(valid_dl)\n",
    "    \n",
    "    print(f'Epoch {e}: | Training Loss: {avg_train_loss:.5f} | Training accuracy: {avg_train_accuracy} | Validation Loss: {avg_valid_loss} | Validation Accuracy: {avg_valid_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "XDIEghli_AdB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2172"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_list = np.array([])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in valid_dl:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_tag = y_pred_tag.squeeze(1).cpu().numpy()\n",
    "        y_pred_list = np.append(y_pred_list, y_pred_tag)\n",
    "                     \n",
    "len(y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1030,  439],\n",
       "       [ 367,  336]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(valid_y, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-1d5703e031ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(valid_y, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO0fLK1v0FHPC7K2mZ78993",
   "mount_file_id": "1Gv9P6j20Iz6psk8kmk82m4fBHJmy2O-r",
   "name": "tabular_nn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
